import os
import tempfile
from pathlib import Path
import json
from aiogram import Router, F
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from faster_whisper import WhisperModel
from pydub import AudioSegment

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–∞ –±–∞–∑–µ LLM –∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î
from config import FFMPEG_PATH
from services.vertex_ai import parse_expense_with_llm
from services.database import add_expense

# –ï—Å–ª–∏ –ø—É—Ç—å –∫ FFmpeg —É–∫–∞–∑–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –∑–∞–¥–∞–µ–º –µ–≥–æ –¥–ª—è pydub
if FFMPEG_PATH:
    AudioSegment.converter = FFMPEG_PATH

router = Router()

MODEL_SIZE = "medium"
# Note: The first time a model is used, it will be downloaded.
# The "medium" model is a few hundred MBs, so the first voice message
# after a restart might take a bit longer to process.
model = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")

from services.cache import temp_data_cache

def create_confirmation_keyboard(data: dict) -> InlineKeyboardMarkup:
    """
    –°–æ–∑–¥–∞–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –î–∞/–ù–µ—Ç –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
    """
    # –£–±–∏—Ä–∞–µ–º confirmation_message, —Ç.–∫. –æ–Ω–æ –Ω–µ –Ω—É–∂–Ω–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    callback_data = data.copy()
    callback_data.pop('confirmation_message', None)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à –∏ –ø–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
    data_key = temp_data_cache.set(callback_data)

    # –¢–µ–ø–µ—Ä—å callback_data —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–π –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–ª—é—á
    yes_callback_data = f"confirm_expense:yes:{data_key}"

    buttons = [
        [
            InlineKeyboardButton(text="‚úÖ –î–∞, –≤—Å–µ –≤–µ—Ä–Ω–æ", callback_data=yes_callback_data),
            InlineKeyboardButton(text="‚ùå –ù–µ—Ç, —É—Ç–æ—á–Ω–∏—Ç—å", callback_data="confirm_expense:no")
        ]
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)

@router.message(F.voice)
async def voice_message_handler(message: Message, bot):
    await message.answer("üé§ –£—Å–ª—ã—à–∞–ª –≤–∞—Å, –Ω–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...")

    voice_dir = Path(tempfile.gettempdir()) / "secretary_bot_voices"
    voice_dir.mkdir(exist_ok=True)
    voice_file_info = await bot.get_file(message.voice.file_id)
    voice_oga_path = voice_dir / f"{message.voice.file_id}.oga"
    await bot.download_file(voice_file_info.file_path, destination=voice_oga_path)
    voice_wav_path = voice_dir / f"{message.voice.file_id}.wav"
    AudioSegment.from_file(voice_oga_path).export(voice_wav_path, format="wav")

    try:
        segments, info = model.transcribe(str(voice_wav_path), beam_size=5, language="ru")
        recognized_text = "".join(segment.text for segment in segments).strip()

        if not recognized_text:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –≤ –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            return

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        parsed_data = parse_expense_with_llm(recognized_text)
        intent = parsed_data.get("intent") if parsed_data else None

        if intent == "add_expense":
            # –ï—Å–ª–∏ LLM —Ä–∞—Å–ø–æ–∑–Ω–∞–ª –∫–æ–º–∞–Ω–¥—É –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—Ö–æ–¥–∞
            keyboard = create_confirmation_keyboard(parsed_data)
            await message.answer(
                text=parsed_data['confirmation_message'],
                reply_markup=keyboard
            )
        elif intent == "get_report":
            # –ï—Å–ª–∏ LLM —Ä–∞—Å–ø–æ–∑–Ω–∞–ª –∫–æ–º–∞–Ω–¥—É –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
            from . import report_handlers
            await report_handlers.handle_report_request(message, parsed_data)
        else:
            # –ï—Å–ª–∏ LLM –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
            await message.answer(
                "–Ø –≤–∞—Å —É—Å–ª—ã—à–∞–ª, –Ω–æ –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —ç—Ç–æ –∫–∞–∫ –∏–∑–≤–µ—Å—Ç–Ω—É—é –º–Ω–µ –∫–æ–º–∞–Ω–¥—É.\n"
                f"**–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:** `{recognized_text}`\n\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."
            )

    except Exception as e:
        await message.answer(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
    finally:
        os.remove(voice_oga_path)
        os.remove(voice_wav_path)