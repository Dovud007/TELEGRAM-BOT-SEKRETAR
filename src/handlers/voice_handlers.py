import os
import tempfile
from pathlib import Path
import json
from aiogram import Router, F
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from faster_whisper import WhisperModel
from pydub import AudioSegment

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–∞ –±–∞–∑–µ LLM –∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î
from config import FFMPEG_PATH
from services.vertex_ai import parse_expense_with_llm
from services.database import add_expense

# –ï—Å–ª–∏ –ø—É—Ç—å –∫ FFmpeg —É–∫–∞–∑–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –∑–∞–¥–∞–µ–º –µ–≥–æ –¥–ª—è pydub
if FFMPEG_PATH:
    AudioSegment.converter = FFMPEG_PATH

router = Router()

MODEL_SIZE = "medium"
# Note: The first time a model is used, it will be downloaded.
# The "medium" model is a few hundred MBs, so the first voice message
# after a restart might take a bit longer to process.
model = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")

def create_confirmation_keyboard(data: dict) -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –î–∞/–ù–µ—Ç –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–∞."""
    # –ú—ã –Ω–µ –º–æ–∂–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å —Ü–µ–ª—ã–π —Å–ª–æ–≤–∞—Ä—å –≤ callback_data, –ø–æ—ç—Ç–æ–º—É —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –µ–≥–æ –≤ JSON
    # –∏ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–Ω –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π.
    # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–± - —Ö—Ä–∞–Ω–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Redis)
    # –∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á. –ù–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø–æ–∫–∞ —Ç–∞–∫.

    # –£–±–∏—Ä–∞–µ–º confirmation_message, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –ª–∏—à–Ω–µ–≥–æ
    callback_data = data.copy()
    callback_data.pop('confirmation_message', None)

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç callback_data
    if len(callback_data['category']) > 20:
        callback_data['category'] = callback_data['category'][:20]

    yes_callback = json.dumps(callback_data)

    buttons = [
        [
            InlineKeyboardButton(text="‚úÖ –î–∞, –≤—Å–µ –≤–µ—Ä–Ω–æ", callback_data=f"confirm_expense:yes:{yes_callback}"),
            InlineKeyboardButton(text="‚ùå –ù–µ—Ç, —É—Ç–æ—á–Ω–∏—Ç—å", callback_data="confirm_expense:no")
        ]
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)

@router.message(F.voice)
async def voice_message_handler(message: Message, bot):
    await message.answer("üé§ –£—Å–ª—ã—à–∞–ª –≤–∞—Å, –Ω–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...")

    voice_dir = Path(tempfile.gettempdir()) / "secretary_bot_voices"
    voice_dir.mkdir(exist_ok=True)
    voice_file_info = await bot.get_file(message.voice.file_id)
    voice_oga_path = voice_dir / f"{message.voice.file_id}.oga"
    await bot.download_file(voice_file_info.file_path, destination=voice_oga_path)
    voice_wav_path = voice_dir / f"{message.voice.file_id}.wav"
    AudioSegment.from_file(voice_oga_path).export(voice_wav_path, format="wav")

    try:
        segments, info = model.transcribe(str(voice_wav_path), beam_size=5, language="ru")
        recognized_text = "".join(segment.text for segment in segments).strip()

        if not recognized_text:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –≤ –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            return

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        parsed_data = parse_expense_with_llm(recognized_text)

        if parsed_data and parsed_data.get('amount'):
            # –ï—Å–ª–∏ LLM –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            keyboard = create_confirmation_keyboard(parsed_data)
            await message.answer(
                text=parsed_data['confirmation_message'],
                reply_markup=keyboard
            )
        else:
            # –ï—Å–ª–∏ LLM –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–∞—Å—Ö–æ–¥
            await message.answer(
                "–Ø –≤–∞—Å —É—Å–ª—ã—à–∞–ª, –Ω–æ –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —ç—Ç–æ –∫–∞–∫ –∫–æ–º–∞–Ω–¥—É –Ω–∞ –∑–∞–ø–∏—Å—å —Ä–∞—Å—Ö–æ–¥–∞.\n"
                f"**–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:** `{recognized_text}`\n\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, —á—Ç–æ –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É, –∏–ª–∏ —Å–∫–∞–∂–∏—Ç–µ –æ —Ä–∞—Å—Ö–æ–¥–µ –±–æ–ª–µ–µ —è–≤–Ω–æ."
            )

    except Exception as e:
        await message.answer(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
    finally:
        os.remove(voice_oga_path)
        os.remove(voice_wav_path)